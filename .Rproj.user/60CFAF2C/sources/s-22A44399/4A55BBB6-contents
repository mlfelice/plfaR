###Some notes from talking to Rad##
#Probably want to do our analysis of individual taxa (eg. methanotrophs) before eliminating rare samples (maybe even rarefying) - make sure working with relative abundance, and be aware that there might be some skew
#rarefy before calculating diversity, but don't want to eliminate any rare taxa
#For multivariate stats, want to eliminate rare taxa and rarefy (which first? maybe eliminate rare taxa)
#For PCA, unconstrained mulitvariates, log transoform and normalize (plot sample distribution to confirm)
#For constrained multivariate, also want to standardize all of the continuous/numeric variables so that weighting is even
#For example, Daoyuan mentioned transforming all variables so that the max is 100, min is 0
#Categorical/factor variables ok
#For all analyses, we probably want to bootstrap - rarefy data multiple times and use the average data
#Jorge even recommnded student do this 100 times

#Some info on multivariate analyses: A. Ramette (2007) Multivariate analyses in microbial ecology, FEMS Microbiology Ecology, 62, 142-160.
  #Recommended not to use PCA or PCoA on community data, because it doesn't handle missing values well


#Script written under R version 3.5.0 
#phyloseq version 1.24.0
#ggplot2 version 2.2.1
#dplyr version 0.7.5
#data.table version 1.11.4
#phyloseq.extended version 0.0.0.9000
#vegan version 2.5.2
#RColorBrewer 1.1.2
#ggvegan version 0.0.9

getRversion()
#3.5.0
RStudio.Version()
#1.1.453

#Load packages and check version
library('phyloseq'); packageVersion('phyloseq')
library('ggplot2'); packageVersion('ggplot2')
library(dplyr); packageVersion('dplyr')
library(ggvegan); packageVersion('ggvegan') #Adds fortify() function used for plotting loadings in ggplot2 multivariate plots

#Not sure if the packages below are still actually used
library(data.table); packageVersion('data.table')
library(phyloseq.extended); packageVersion('phyloseq.extended')
library(vegan);packageVersion('vegan') #rarefaction curve
library(RColorBrewer); packageVersion('RColorBrewer') #Used for relative abundance bar plots

library(plyr)
library(matrixStats)
library(reshape2)


#Set theme for ggplot
theme_set(theme_bw())

#2. Load and prepare metadata
#-----------------------------------

sam_metad = read.csv('C:/Users/Mark/Dropbox/Work Computer/Research/PCRR/Sequencing/metadata/20180328_MLF02182018_metadata_phyloseq.csv', row.names = 1, header = TRUE)

#Set the directory containing gas interpolation csv files (these were generated by Python script - Delauney interpolatino)
interp_dir = 'C:/Users/Mark/Dropbox/Work Computer/Research/PCRR/Sequencing/metadata/Gas contours'

#Make list of files in the directory
list_of_interpolations = lapply(Sys.glob(paste0(interp_dir, '/', '*delauneyCH4.txt')), read.table, sep = ',')

#Define a character vector containing the dates in the metadata
vector_of_dates = as.character(unique(sam_metad$Date[!is.na(sam_metad$Date)])) #Requires that the metadata already loaded

names(list_of_interpolations) <- vector_of_dates

#Function for searching the interpolation arrays for concentration value based on provided spatial data
find_interp_val2 = function(xcoord, ycoord, date, gas_data_list)
{
  
  x2 = round(xcoord/3 * 500)
  y2 = round((ycoord/100) / 1.77 * 500)
  return(gas_data_list[[as.character(date)]][y2+1, x2+1]) #Need to add 1 to each x and y coordinate because the array is indexed starting at 1,1
}


list1 = vector('list', nrow(sam_metad)) #generate empty list to house results
names(list1) = rownames(sam_metad) #Name list elements to have sample names
for(i in 1:nrow(sam_metad)){
  list1[[i]] = find_interp_val2(sam_metad$distance[i], sam_metad$Depth_cm[i], sam_metad$Date[i], list_of_interpolations) #find the CH4 concentration corresponding to each row in metadata dataframe
}
CH4_conc = data.frame(CH4_conc = unlist(list1)) #convert list to dataframe >> element names become row names

sam_metad = merge(sam_metad, CH4_conc, by = 0, all = TRUE) #Merge CH4 concentration data to metadata, matched on rows - this is a full merge, all rows will be preserved

sam_metad = sam_metad %>% select(-CH4conc) %>% #Remove the old, empty methane column
  tibble::column_to_rownames('Row.names') #The merge turned row names into a column, so we must convert back to rownames to allow creation of phyloseq object

#replace NaN with NA
sam_metad$CH4_conc[is.nan(sam_metad$CH4_conc)] = NA

#remove all objects used to create te metadata
#rm('CH4_conc', 'list_of_interpolations', 'list1', 'i', 'interp_dir', 'vector_of_dates',' find_interp_val2')
rm(list=setdiff(ls(), "sam_metad"))

sam_metad_trim = sam_metad %>% #clean metadata dataframe
  select(Sampling.Event,
         Interval_cm,
         distance.f,
         distance,
         Depth_cm,
         GWC,
         Clay,
         CH4_conc
         #-Barcode.sequence, 
         #-Index.1..i7..Description,
         #-Interval_num
         ) %>%
  tibble::rownames_to_column() %>%
  #be careful to make sure you remove or change the name of x and y columns. Otherwise they throw an error when plotting because the ggrare function merges the sample metadata to an internally generated label dataframe taht has columns named x and y
  dplyr::rename(distance_cat = distance.f) #conflict with plyr's rename() means you need to specify the package explicitly
  
rescale = function(vector){ #Function rescales all of the numeric variables to have a min value of 0, max of 1 to match relative abundance of OTUs
  scaled = (vector - min(vector, na.rm = T)) * 1/(max(vector, na.rm = T)-min(vector, na.rm = T))
  return(scaled)
}

sam_metad_trim[, 5:9] = data.frame(lapply(sam_metad_trim[5:9], rescale)) #This preps the metadata for multivariate analyses by scaling
  
sam_metad_trim = sam_metad_trim %>% tibble::column_to_rownames('rowname')

rm(sam_metad)

sam_metad_trim['Sampling.Event'] <- lapply(sam_metad_trim['Sampling.Event'], factor)



#str(sam_metad_trim) #display structure of an object - in this case see what class all the columns are

#2. Create Phyloseq object from DADA2 outputs and metadata table
#---------------------------------


#Load the sequence table and taxonomy table
#NOTE: these are on a flash drive, so may need to change the drive if using a different computer or port
seqtab.nochim2 <- readRDS('D:/Work Computer/Process_MLF02162018v3/seqtab_nochim_MLF02162018-2.rds')
tax_table_SILVA <- readRDS('D:/Work Computer/Process_MLF02162018v3/taxa_SILVA_MLF02162018.rds')

#Combine files into phyloseq object
ps <- phyloseq(otu_table(seqtab.nochim2, taxa_are_rows = FALSE),
               sample_data(sam_metad_trim),
               tax_table(tax_table_SILVA))
#remove the tax table and otu table from the workspace to save some room
rm(seqtab.nochim2, tax_table_SILVA)

#---Accessor functions for pulling various pieces of data from the Phyloseq objects---
#rank_names(ps)
#sample_names(ps)
#sample_variables(ps)
#taxa_sums(ps) #Generates the number of reads for each ASV
#sample_sums(ps) #Generates the number of reads contained in each sample (ie. sequencing depth)
#sample_data(ps)
#otu_table(ps) #Returns the OTU table component of the phyloseq object
###----

#3. Sample selection
#----------------------
#Because our sequencing run included a few different sample types that we don't necessarily want to run together, we need to filter some of these out before downstream analysis
#Blank - DNA from the negative controls during library prep
#B samples - these were microcosm samples
#Within these, B2-0, B2-9, and B3-0 were from the sterile control, and may need removal to see good trends, even within the microcosm subset
#Subset of PCRR samples were included from alternate depth intervals as consistency check in case we ran another sequencing lane with the alternate depths

exclude_samples <- sample_names(ps)[grepl('^B.*|-2$|-8$|-16$', sample_names(ps))] #grepl() is short for grep logic and returns a logic vector with TRUE/FALSE indicating whether there was a partial match or not - using this to subset is the same as normal logical expression; grepl takes the regular expression as first argument and vector to be tested as the second
ps_PCRR <- subset_samples(ps, !sample_names(ps) %in% exclude_samples) #subset samples to remove samples included in the list generated above
rm(exclude_samples)

#Samples that don't belong to Bacteria or Archaea are probably erroneous, since others don't have 16S; also filter out Mitochondria, Chloroplasts, and reads that could not be assigned at the Phylum level
ps_PCRR <- subset_taxa(ps_PCRR, (Kingdom == 'Bacteria' | Kingdom == 'Archaea') &
                         Class != 'Mitochondria' &
                         Family != 'Chloroplast' &
                         !is.na(Phylum) & !Phylum %in% c('', 'uncharacterized'))

sample_names(ps_PCRR) #verify that we have the desired samples

rm(ps)

#Remove OTU's that aren't represented in any samples - I don't think there should normally be any, but there are probably some from the blank/undetermined samples and the microcosm samples that we're not analyzing
ps_PCRR <- prune_taxa(taxa_sums(ps_PCRR) > 0, ps_PCRR) #taxa_sum()returns the sum of reads for each ASV, which should be 0 if not present in any samples

#One sample was almost completely dominated by a single ASV, which is very suspicious for soil, so we should filter samples with majority single ASV
#First, generate a dataframe with the TRUE/FALSE values, FALSE indicating that the sample has ASV with greater abundance than the threshold
#This defines the function
spurious_samp_df <- function(physeq)
{
  spur_df <- apply(X = otu_table(physeq),
                   MARGIN = ifelse(taxa_are_rows(physeq), yes = 2, no = 1), #MARGIN specifies whether should be applied over rows (1) or columns (2); taxa_are_rows() returns TRUE if each row represents a taxon, FALSE if taxa are in columns; this line is just to make the apply() function work no matter how your data are set up
                   FUN = function(x){all((x/sum(x))<0.9)}) #This function sums the number of rows under each taxon with at least one read; x>0 returns TRUE or FALSE for each cell, so sum() takes totals the number of TRUE values rather than the value of the cell itself
  #Append abundance/total read count data and taxonomy; this function just selects the prevalence, abundance, and the taxonomy table and combines in a dataframe
  spur_df <- data.frame(Sample = sample_names(physeq),
                        SpuriousTF = spur_df)
  return(spur_df)
}

#Run the above function to ID spurious samples in dataframe
rem_spur_samps <- spurious_samp_df(ps_PCRR)
rem_spur_samps <- as.character(rem_spur_samps$Sample[rem_spur_samps$SpuriousTF == FALSE]) #convert dataframe to vector

#Remove samples contained in the vector of spurious samples
ps_PCRR <- subset_samples(ps_PCRR, !sample_names(ps_PCRR) %in% rem_spur_samps)
sample_names(ps_PCRR) #Verify that samples were properly filtered
rm(rem_spur_samps)


#Multivariate plots with vegan - rarefy
#------------------------------
#relative abundance transformation does nothing after rarefying; the NMDS plots are robust to normalization if rarefied (scaling metadata has no effect on the visualization of loadings)
#Using relative abundance without rarefying does alter the clustering to some degree
#cannot use scaled data (0 mean) for the OTU data, as the negative numbers don't work with at least bray
#Rarefy samples before running multivariate stats - I think this is currently our best option (other than maybe metagenomeseq)
set.seed(100)

ps_rare = rarefy_even_depth(ps_PCRR, rngseed = FALSE, replace = FALSE)
ps_rare = transform_sample_counts(ps_rare, function(x){x/sum(x)})

#to make sure datafrmes are in the same order >> all.equal(rownames(otu_table(physeq)), rownames(sample_data(physeq)))
all.equal(rownames(otu_table(ps_rare)), rownames(sample_data(ps_rare)))
#----


set.seed(100)
ps_nmds = metaMDS(otu_table(ps_rare), dist = 'bray') 

#"The stress, or the disagreement between 2-D configuration and predicted values from the regression"
#A good rule of thumb: stress > 0.05 provides an excellent representation in reduced dimensions, > 0.
#Other opinion: 1 is great, >0.2 is good/ok, and stress > 0.3 provides a poor representation
stressplot(ps_nmds) ##"shows scatter around the regression between the interpoint distances in the final configuration (i.e., the distances between each pair of communities) against their original dissimilarities." "Large scatter around the line suggests that original dissimilarities are not well preserved in the reduced number of dimensions. Looks pretty good in this case."

########
#Plotting NMDS with ggplot2 - all samples
nmds_fortified = fortify(ps_nmds)

sam_metad_mv = cbind(Label = rownames(data.frame(sample_data(ps_rare))), 
                     data.frame(sample_data(ps_rare)))
nmds_fortified = left_join(nmds_fortified, sam_metad_mv, by = 'Label')
#Calculate environmental vectors for overlay
ps_nmds_env = envfit(ps_nmds, data.frame(sample_data(ps_rare)[,4:8]), na.rm = TRUE)
nmds_env_fort = fortify(ps_nmds_env)

#NMDS without vectors
ggplot() +
  geom_point(data = nmds_fortified[nmds_fortified$Score == 'sites',], aes(x = NMDS1, y = NMDS2, color = Interval_cm),
             alpha = 0.75) +
  stat_ellipse(data = nmds_fortified[nmds_fortified$Score == 'sites',],
               aes(group = Interval_cm, x = NMDS1, y = NMDS2, color = Interval_cm))


#NMDS plot with environmental vectors
arrow_mul = 2 #arrow multiplier, scales loading vectors to better fit plotting space
nmds_vec_all = ggplot() +
  geom_point(data = nmds_fortified[nmds_fortified$Score == 'sites',], aes(x = NMDS1, y = NMDS2, color = Interval_cm, shape = Sampling.Event),
             alpha = 0.75) +
  stat_ellipse(data = nmds_fortified[nmds_fortified$Score == 'sites',],
               aes(group = Interval_cm, x = NMDS1, y = NMDS2, color = Interval_cm)) +
  geom_segment(data = nmds_env_fort, 
               aes(x = 0, y = 0, xend = NMDS1*arrow_mul, yend = NMDS2*arrow_mul),
               arrow = arrow(length = unit(0.2, 'cm')), color = 'indianred') +
  geom_text(data = nmds_env_fort, 
            aes(x = NMDS1*arrow_mul, y = NMDS2*arrow_mul, label = Label)) +
  coord_fixed()
ggsave('C:/Users/Mark/Dropbox/Work Computer/Research/PCRR/Sequencing/analysis/phyloseq/output/plots/20180617_mlf02162018v3_physeq_relative-abundance_nmds_all.svg', plot = nmds_vec_all, device = 'svg')

#####
#Function that wraps NMDS generation and plotting into one function so that we can easily try plots broken down into subsets
markplot_nmds = function(physeq, distance_method = 'bray', subset_var, subset_value, color, shape, ellipse, vector_scale = 2){
  
  s = sample_data(physeq)[sample_data(physeq)[,subset_var] == subset_value]
  #s = sample_data(ps_PCRR)[sample_data(ps_PCRR)[,subset_var] == subset_value]
  #ps_sub = subset_samples(ps_PCRR, sample_names(ps_PCRR) %in% rownames(s))
  s_rowname = rownames(s)
  print(s_rowname)
  
  ps_sub = prune_samples(s_rowname, physeq) 
  
  #generate nmds ordination object
  set.seed(100)
  
  ps_nmds = metaMDS(otu_table(ps_sub), dist = distance_method) 
  
  nmds_fortified = fortify(ps_nmds)
  
  sam_metad_mv = cbind(Label = rownames(data.frame(sample_data(ps_sub))), 
                       data.frame(sample_data(ps_sub)))
  nmds_fortified = left_join(nmds_fortified, sam_metad_mv, by = 'Label')
  
  #Calculate environmental vectors for overlay
  ps_nmds_env = envfit(ps_nmds, data.frame(sample_data(ps_sub)[,4:8]), na.rm = TRUE)
  print(ps_nmds_env)
  nmds_env_fort = fortify(ps_nmds_env)
  
  
  # Set colors for plotting
  plot_color1 <- c(
    '#107AE5', '#EFA71A', 'green3', '#0D4987', 'deeppink2', 'sienna', 'black', '#DF16A1',
    '#F8DCA5', '#A5CEF8', '#BDF698', '#F188D1',
    '#A06E0E', '#9B086E',
    '#1EEBB2', '#EC223E',
    '#A6F7E0', '#F4909E', '#68EC13',
    '#0C8D68', '#990B1E'
  )

  #NMDS plot with environmental vectors
  ggplot() +
    geom_point(data = nmds_fortified[nmds_fortified$Score == 'sites',], aes_string(x = 'NMDS1', y = 'NMDS2', color = color, shape = shape),
               alpha = 0.75) +
    scale_color_manual(values = plot_color1, name = "Depth Interval (cm)", 
                       breaks = c('0-3.75', '11.25-18.75', '33.75-41.25', '63.75-71.25', '93.75-101.25', '123.75-131.25'),
                       labels = c('0-3.8', '11.3-18.8', '33.8-41.3', '63.8-71.3', '93.8-101.3', '123.8-131.3')) +
    scale_shape_discrete(name = "Sampling Event") +
    stat_ellipse(data = nmds_fortified[nmds_fortified$Score == 'sites',],
                 aes_string(group = ellipse, x = 'NMDS1', y = 'NMDS2', color = ellipse, alpha = 0.75)) +
    scale_color_manual(values = plot_color1, name = "Depth Interval (cm)", 
                       breaks = c('0-3.75', '11.25-18.75', '33.75-41.25', '63.75-71.25', '93.75-101.25', '123.75-131.25'),
                       labels = c('0-3.8', '11.3-18.8', '33.8-41.3', '63.8-71.3', '93.8-101.3', '123.8-131.3')) +
    geom_segment(data = nmds_env_fort, 
                 aes(x = 0, y = 0, xend = NMDS1*vector_scale, yend = NMDS2*vector_scale),
                 arrow = arrow(length = unit(0.2, 'cm')), color = 'red') + #'indianred'
    geom_text(data = nmds_env_fort, 
              aes(x = NMDS1*vector_scale, y = NMDS2*vector_scale, label = Label)) +
    theme(aspect.ratio = 1)
}

nmds_vec_prox = markplot_nmds(ps_rare, distance_method = 'bray', subset_var = 'distance_cat', subset_value = 'Proximal', color = 'Interval_cm', shape = 'Sampling.Event', ellipse = 'Interval_cm')
nmds_vec_dist = markplot_nmds(ps_rare, distance_method = 'bray', subset_var = 'distance_cat', subset_value = 'Distal', color = 'Interval_cm', shape = 'Sampling.Event', ellipse = 'Interval_cm')

nmds_vec_prox
nmds_vec_dist

ggsave('C:/Users/Mark/Dropbox/Work Computer/Research/PCRR/Sequencing/analysis/phyloseq/output/plots/20180912_mlf02162018v3_physeq_relative-abundance_nmds_prox.svg', plot = nmds_vec_prox, device = 'svg')
ggsave('C:/Users/Mark/Dropbox/Work Computer/Research/PCRR/Sequencing/analysis/phyloseq/output/plots/20180912_mlf02162018v3_physeq_relative-abundance_nmds_dist.svg', plot = nmds_vec_dist, device = 'svg')

###########
#PCA
ps_pca = rda(otu_table(ps_rare))
ps_pca_env = envfit(ps_pca, data.frame(sample_data(ps_rare)[,4:8]), na.rm = TRUE)

sam_metad_mv = cbind(Label = rownames(data.frame(sample_data(ps_rare))), 
                     data.frame(sample_data(ps_rare)))

pca_fortified = fortify(ps_pca)
pca_fortified = left_join(pca_fortified, sam_metad_mv, by = 'Label')

pca_env_fort = fortify(ps_pca_env)

### --- This is a little side note experimenting with slimming down the biplot arrows so that we can actually make sense of the biplot
#This sorts the species data and selects the top 20 ASVs to display
pca_fortified2 = pca_fortified %>% mutate(PCdist = abs(sqrt(PC1^2 + PC2^2)))
a = pca_fortified2[pca_fortified2$Score == 'species',]
pca_fortified2 = rbind(pca_fortified2[pca_fortified2$Score == 'sites',],
                       a[order(-a$PCdist),][1:10,])
pca_fortified2 = merge(pca_fortified2, tibble::rownames_to_column(as.data.frame(tax_table(ps_rare)), var = 'Label'), by = 'Label')

arrow_mul = 2.5
ggplot() +
  geom_point(data = pca_fortified[pca_fortified$Score == 'sites',], aes(x = PC1, y = PC2, color = Interval_cm),
             alpha = 0.75) +
  stat_ellipse(data = pca_fortified[pca_fortified$Score == 'sites',],
               aes(group = Interval_cm, x = PC1, y = PC2, color = Interval_cm)) +
  #geom_point(data = pca_fortified2[pca_fortified2$Score == 'species',], 
  #                          aes(x = PC1, y = PC2)) +
  #geom_text(data = pca_fortified2[pca_fortified2$Score == 'species',], 
  #                    aes(x = PC1, y = PC2, label = Family))
  geom_segment(data = pca_fortified2[pca_fortified2$Score == 'species',], 
               aes(x = 0, y = 0, xend = PC1*arrow_mul, yend = PC2*arrow_mul),
               arrow = arrow(length = unit(0.2, 'cm')), color = 'indianred') +
  geom_text(data = pca_fortified2[pca_fortified2$Score == 'species',], 
            aes(x = PC1*arrow_mul, y = PC2*arrow_mul, label = Family))
###
arrow_mul = 2.50
ggplot() +
  geom_point(data = pca_fortified[pca_fortified$Score == 'sites',], aes(x = PC1, y = PC2, color = Interval_cm),
             alpha = 0.75) +
  stat_ellipse(data = pca_fortified[pca_fortified$Score == 'sites',],
               aes(group = Interval_cm, x = PC1, y = PC2, color = Interval_cm)) +
  geom_segment(data = pca_env_fort, 
               aes(x = 0, y = 0, xend = PC1*arrow_mul, yend = PC2*arrow_mul),
               arrow = arrow(length = unit(0.2, 'cm')), color = 'indianred') +
  geom_text(data = pca_env_fort, 
            aes(x = PC1*arrow_mul, y = PC2*arrow_mul, label = Label))

#CCA
ps_cca = cca(formula = otu_table(ps_rare) ~ GWC + Depth_cm + Clay + Sampling.Event + distance + CH4_conc, data = as(sample_data(ps_rare), 'data.frame'), na.exclude)

#ggvegan info: https://github.com/gavinsimpson/ggvegan
cca_fortified = fortify(ps_cca)
sam_metad_mv = cbind(Label = rownames(data.frame(sample_data(ps_rare))), 
                     data.frame(sample_data(ps_rare)))
cca_fortified = left_join(cca_fortified, sam_metad_mv, by = 'Label')

arrow_mul = 2.5 #arrow multiplier, scales loading vectors to better fit plotting space

ggplot() +
  geom_point(data = cca_fortified[cca_fortified$Score == 'sites',], aes(x = CCA1, y = CCA2, color = Interval_cm, shape = Sampling.Event),
             alpha = 0.75) +
  geom_segment(data = cca_fortified[cca_fortified$Score == 'biplot',], 
               aes(x = 0, y = 0, xend = CCA1*arrow_mul, yend = CCA2*arrow_mul),
               arrow = arrow(length = unit(0.2, 'cm')), color = 'indianred') +
  geom_text(data = cca_fortified[cca_fortified$Score == 'biplot',], 
            aes(x = CCA1*(arrow_mul*1.15), y = CCA2*(arrow_mul*1.15), label = Label)) + 
  stat_ellipse(data = cca_fortified[cca_fortified$Score == 'sites',],
               aes(group = Interval_cm, x = CCA1, y = CCA2, color = Interval_cm))

#Repeat CCA from above without methane
ps_cca = cca(formula = otu_table(ps_filter_rare) ~ GWC + Depth_cm + Clay + Date + distance, data = as(sample_data(ps_filter_rare), 'data.frame'), na.exclude)

cca_fortified = fortify(ps_cca)
sam_metad_mv = cbind(Label = rownames(data.frame(sample_data(ps_filter_rare))), 
                     data.frame(sample_data(ps_filter_rare)))
cca_fortified = left_join(cca_fortified, sam_metad_mv, by = 'Label')

arrow_mul = 2.5 #arrow multiplier, scales loading vectors to better fit plotting space

ggplot() +
  geom_point(data = cca_fortified[cca_fortified$Score == 'sites',], aes(x = CCA1, y = CCA2, color = Interval_cm, shape = Sampling.Event),
             alpha = 0.75) +
  geom_segment(data = cca_fortified[cca_fortified$Score == 'biplot',], 
               aes(x = 0, y = 0, xend = CCA1*arrow_mul, yend = CCA2*arrow_mul),
               arrow = arrow(length = unit(0.2, 'cm')), color = 'indianred') +
  geom_text(data = cca_fortified[cca_fortified$Score == 'biplot',], 
            aes(x = CCA1*(arrow_mul*1.15), y = CCA2*(arrow_mul*1.15), label = Label)) + 
  stat_ellipse(data = cca_fortified[cca_fortified$Score == 'sites',],
               aes(group = Interval_cm, x = CCA1, y = CCA2, color = Interval_cm))

markplot_cca = function(physeq, subset_var, subset_value, color, shape, ellipse, vector_scale = 2){
  set.seed(100)
  s = sample_data(physeq)[sample_data(physeq)[,subset_var] == subset_value]
  
  s_rowname = rownames(s)
  
  ps_sub = prune_samples(s_rowname, physeq) 
  
  ps_cca = cca(formula = otu_table(ps_sub) ~ GWC + Depth_cm + Clay + Sampling.Event + distance + CH4_conc, data = as(sample_data(ps_sub), 'data.frame'), na.exclude)
  
  #ggvegan info: https://github.com/gavinsimpson/ggvegan
  cca_fortified = fortify(ps_cca)
  sam_metad_mv = cbind(Label = rownames(data.frame(sample_data(ps_sub))), 
                       data.frame(sample_data(ps_sub)))
  cca_fortified = left_join(cca_fortified, sam_metad_mv, by = 'Label')
  
  arrow_mul = 2.5 #arrow multiplier, scales loading vectors to better fit plotting space
  
  ggplot() +
    geom_point(data = cca_fortified[cca_fortified$Score == 'sites',], aes_string(x = 'CCA1', y = 'CCA2', color = color, shape = shape),
               alpha = 0.75) +
    geom_segment(data = cca_fortified[cca_fortified$Score == 'biplot',], 
                 aes(x = 0, y = 0, xend = CCA1*arrow_mul, yend = CCA2*arrow_mul),
                 arrow = arrow(length = unit(0.2, 'cm')), color = 'indianred') +
    geom_text(data = cca_fortified[cca_fortified$Score == 'biplot',], 
              aes(x = CCA1*(arrow_mul*1.15), y = CCA2*(arrow_mul*1.15), label = Label)) + 
    stat_ellipse(data = cca_fortified[cca_fortified$Score == 'sites',],
                 aes_string(group = ellipse, x = 'CCA1', y = 'CCA2', color = ellipse))
  
}

markplot_cca(ps_rare, 
             subset_var = 'distance_cat', 
             subset_value = 'Proximal', 
             ellipse = 'Interval_cm', 
             color = 'Interval_cm', 
             shape = 'Sampling.Event')
markplot_cca(ps_rare, 
             subset_var = 'distance_cat', 
             subset_value = 'Distal', 
             ellipse = 'Interval_cm', 
             color = 'Interval_cm', 
             shape = 'Sampling.Event')
markplot_cca(ps_rare, 
             subset_var = 'Interval_cm', 
             subset_value = '93.75-101.25', 
             ellipse = 'distance_cat', 
             color = 'distance_cat', 
             shape = 'Sampling.Event')
